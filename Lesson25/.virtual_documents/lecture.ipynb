import pandas as pd
import numpy as np

import plotly.express as px

# model evaluation
from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')














def preprocess_data(df:pd.DataFrame) -> pd.DataFrame:
    df.date = pd.to_datetime(df.date)
    df['day_of_week'] = df['date'].dt.day_name()
    return df

# load train dataset | convert datatype of "date" column from "object" to "datetime"
stores_df = pd.read_csv("data/train.csv")
stores_df = preprocess_data(stores_df)


stores_df


# shape of train set
print(f"Stores data shape - {stores_df.shape}")


# amount of unique stores
print(f'Amount of stores - {stores_df["store_nbr"].nunique()}')


# shape for 1 store
store_nbr = 1
store_data_shape = stores_df[stores_df["store_nbr"] == store_nbr].shape

print(f'Data shape for 1 store - {store_data_shape}')


# sum up sales for the day
def sum_sales_per_day(df: pd.DataFrame, store_number:int=1) -> pd.DataFrame:
    day_level_df = df[df["store_nbr"]==store_number]\
        [
            ["date", "sales", "day_of_week"]
        ]\
            .groupby("date").agg(
                {
                    "sales": "sum",
                    "day_of_week": "first"
                }).reset_index()

    return day_level_df


day_level_df = sum_sales_per_day(stores_df)


day_level_df.head()


day_level_df.shape


# visualize sales
fig = px.line(day_level_df, x='date', y=["sales"], markers=True, title="Store sales")
fig.show()


# plot sales per each day of week
fig = px.box(day_level_df, x='day_of_week', y="sales", color="day_of_week",
             boxmode="overlay", points='all')
fig.update_layout(
    margin=dict(l=20, r=20, t=30, b=20),
    paper_bgcolor="LightSteelBlue",
    width=1400,
    height=700,
    title='Weekdays sales distribution',
)


from statsmodels.tsa.stattools import adfuller

adftest = adfuller(day_level_df[:30].set_index('date')['sales'].dropna()) #autolag = 'AIC', regression = 'n')
print("ADF Test Results")
print("Null Hypothesis: The series has an Unit Root")
print("P-Value:", adftest[1])
print("Note: If P-Value is smaller than 0.05, we reject the null Hypothesis and the series is Stationary")





# replace Zero values on NaN
day_level_df["sales"] = day_level_df["sales"].mask(day_level_df["sales"] == float(0), None)
day_level_df.head()


# amount of Nan values
day_level_df["sales"].isna().sum()
print(f'NaN value counts - {day_level_df["sales"].isna().sum()}')


# load holidays event
event_df = pd.read_csv("data/holidays_events.csv")
event_df = preprocess_data(event_df)

event_df.head()


# merge sales data to look at the
event_df['date'] = pd.to_datetime(event_df['date'])

day_level_df[day_level_df['sales'].isna()].merge(
    event_df[["date", "description"]],
    how="left"
)





# fill NaN with zero value
day_level_df.fillna(0).head()





# fill NaN with Mean value
nan_indexs = day_level_df[day_level_df["sales"].isna()].index
day_level_df.fillna(day_level_df["sales"].mean()).iloc[nan_indexs]





# Fill NaN with Last Value with .ffill()
day_level_df.ffill().iloc[nan_indexs]


# simple example of ffill()
pd.Series([2, None, None, None, 4]).ffill()





# apply interpolation
day_level_df.interpolate().iloc[nan_indexs]


# simple example of interpolation
pd.Series([1, 2, None, None, None, 4, 5, 7]).interpolate()


(4-2)/4


# choose filling zeroes for this dataset
day_level_df["sales"] = day_level_df["sales"].mask(day_level_df["sales"] == float(0), None)
day_level_df.fillna(0, inplace=True)





def simple_moving_average(data, N):
    SMA = []
    for i in range(N-1, len(data)):
        total = sum([data[j] for j in range(i-N+1, i+1)])
        SMA.append(total/N)
    return np.array(SMA)


# mannual implementation of Moving Average
window = 30
manual_MA_dataset = day_level_df.copy()
manual_MA_dataset.loc[window-1:, 'MA_score'] = simple_moving_average(manual_MA_dataset['sales'], window)

# Plot actual and forecasted data
fig = px.line(manual_MA_dataset, x='date', y=["sales", "MA_score"], markers=True, title="MA forecast")

# Show plot
fig.show()


# Calculate Simple Moving Average
window_size = 30
MA_dataset = day_level_df.copy()
# train, test = train_day_sales_df[:-window_size], train_day_sales_df[-window_size:]
MA_dataset['MA_score'] = MA_dataset['sales'].rolling(window=window_size).mean()

# Plot actual and forecasted data
fig = px.line(MA_dataset, x='date', y=["sales", "MA_score"], markers=True, title="MA forecast")

# Show plot
fig.show()





# model evaluation
def evaluate_forecasting_model(actual_values:pd.Series, predicted_values:pd.Series, round_nbr:int=2) -> None:
    mape = mean_absolute_percentage_error(
        actual_values,
        predicted_values
    )
    mae = mean_absolute_error(
        actual_values,
        predicted_values
    )
    mse = mean_squared_error(
        actual_values,      
        predicted_values
    )

    print(f"MAE - {round(mae, round_nbr)}")
    print(f"MSE - {round(mse, round_nbr)}")
    print(f"MAPE - {round(mape, round_nbr)}")

evaluate_forecasting_model(
    actual_values=MA_dataset[-window_size:]['sales'],
    predicted_values=MA_dataset[-window_size:]['MA_score']
)





from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly, plot_cross_validation_metric, add_changepoints_to_plot


# preprocess data to needed format
fbp_set = day_level_df[['date', 'sales']]
fbp_set.rename(columns={"date": "ds", "sales":"y"}, inplace=True)
fbp_set.fillna(0, inplace=True)
fbp_set.head()


# split dataframe on train and test
window = 30
train, test = fbp_set[:-window], fbp_set[-window:]


# init and fit the model
m = Prophet()
m.fit(train)


# Create Future dates
future_sales = m.make_future_dataframe(periods=30)

# Predict sales
forecast = m.predict(future_sales)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()


# display components
plot_components_plotly(m, forecast, figsize=(1000, 300))


plot = plot_plotly(m, forecast, figsize=(1400, 700))
plot.update_layout(showlegend=True)


# plot changepoint duting time series data
fig = m.plot(forecast)
a = add_changepoints_to_plot(fig.gca(), m, forecast)


# merge test set with forecasted values
benchmark_df = test.merge(forecast[["ds", "yhat"]], on="ds", how="left")

# Plot actual and forecasted data
fig = px.line(benchmark_df, x='ds', y=["y", "yhat"], markers=True, title="Prophet forecast")
# Show plot 
fig.show()


# evaluate forecasting using Mean Absolute Percentage Error (MAPE)
evaluate_forecasting_model(
    actual_values=benchmark_df['y'],
    predicted_values=benchmark_df['yhat'],
    round_nbr=3
)





# load holidays event
event_df = pd.read_csv("data/holidays_events.csv")
event_df = preprocess_data(event_df)

event_df.head()


# preprocess holidays dataframe
holiday_df = event_df.copy()
holiday_df.rename(columns={"date": "ds", "description":"holiday"}, inplace=True)
holiday_df = holiday_df[["ds", "holiday"]]
holiday_df.head()


# init and fit the model
m = Prophet(holidays=holiday_df)
m.fit(train)

# Create Future dates
future_sales = m.make_future_dataframe(periods=30)

# Predict Prices
forecast = m.predict(future_sales)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()


plot_components_plotly(m, forecast, figsize=(1000, 300))


benchmark_df = test.merge(forecast[["ds", "yhat"]], on="ds", how="left")

# Plot actual and forecasted data
fig = px.line(benchmark_df, x='ds', y=["y", "yhat"], markers=True, title="Prophet forecast using event data")
# Show plot
fig.show()


# evaluate forecasting using Mean Absolute Percentage Error (MAPE)
evaluate_forecasting_model(
    actual_values=benchmark_df['y'],
    predicted_values=benchmark_df['yhat'],
    round_nbr=3
)












